{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('mnist_train.csv')\n",
    "test = pd.read_csv('mnist_test.csv')\n",
    "submit = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>59995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>59996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>59997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>59998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>59999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0    0    1    2    3    4    5    6    7    8  ...  775  776  \\\n",
       "0               0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1               1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2               2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3               3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "4               4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...           ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "59995       59995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "59996       59996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "59997       59997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "59998       59998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "59999       59999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "       777  778  779  780  781  782  783  784  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  9.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "59995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  8.0  \n",
       "59996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  \n",
       "59997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  \n",
       "59998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  6.0  \n",
       "59999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  8.0  \n",
       "\n",
       "[60000 rows x 786 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(['Unnamed: 0', '784'], axis = 1) #해당 레이블은 각각 index. label 이므로 제거\n",
    "test_x = test.drop(['Unnamed: 0'], axis = 1)\n",
    "train_y = (train['784'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_tensor = torch.FloatTensor(train_x.values).to(device)\n",
    "train_y_tensor = torch.LongTensor(train_y.values).to(device)\n",
    "test_x_tensor = torch.FloatTensor(test_x.values).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_x_tensor, train_y_tensor)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=2000,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = torch.nn.Linear(784,512,bias=True)\n",
    "linear2 = torch.nn.Linear(512,512,bias=True)\n",
    "linear3 = torch.nn.Linear(512,512,bias=True)\n",
    "linear4 = torch.nn.Linear(512,512,bias=True)\n",
    "linear5 = torch.nn.Linear(512,10,bias=True)\n",
    "relu = torch.nn.ReLU()\n",
    "dropout = torch.nn.Dropout(p=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0002, -0.0084,  0.0340,  ...,  0.0659,  0.0017,  0.0082],\n",
       "        [ 0.0732, -0.0465, -0.0325,  ...,  0.1050,  0.0456, -0.0786],\n",
       "        [ 0.0072, -0.0874,  0.0975,  ...,  0.0975,  0.0515,  0.0245],\n",
       "        ...,\n",
       "        [ 0.0794,  0.0860, -0.0077,  ...,  0.0270,  0.0412,  0.0247],\n",
       "        [ 0.0821,  0.0229,  0.0508,  ..., -0.0335, -0.0429, -0.0587],\n",
       "        [-0.0008,  0.0162,  0.0755,  ...,  0.1017, -0.0163,  0.0126]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Init => Xavier Init\n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)\n",
    "torch.nn.init.xavier_uniform_(linear4.weight)\n",
    "torch.nn.init.xavier_uniform_(linear5.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(linear1,relu,dropout,\n",
    "                            linear2,relu,dropout,\n",
    "                            linear3,relu,dropout,\n",
    "                            linear4,relu,dropout,\n",
    "                            linear5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss().to(device) # softmax 내부적으로 계산\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 12.465585709\n",
      "Epoch: 0002 cost = 0.984031379\n",
      "Epoch: 0003 cost = 0.682807446\n",
      "Epoch: 0004 cost = 0.552272975\n",
      "Epoch: 0005 cost = 0.473981023\n",
      "Epoch: 0006 cost = 0.419978589\n",
      "Epoch: 0007 cost = 0.375250459\n",
      "Epoch: 0008 cost = 0.338312387\n",
      "Epoch: 0009 cost = 0.308492362\n",
      "Epoch: 0010 cost = 0.285027623\n",
      "Epoch: 0011 cost = 0.263787240\n",
      "Epoch: 0012 cost = 0.246811911\n",
      "Epoch: 0013 cost = 0.231308982\n",
      "Epoch: 0014 cost = 0.215484187\n",
      "Epoch: 0015 cost = 0.202350900\n",
      "Epoch: 0016 cost = 0.190964177\n",
      "Epoch: 0017 cost = 0.180360273\n",
      "Epoch: 0018 cost = 0.171786368\n",
      "Epoch: 0019 cost = 0.164351046\n",
      "Epoch: 0020 cost = 0.153207928\n",
      "Epoch: 0021 cost = 0.148563653\n",
      "Epoch: 0022 cost = 0.141443074\n",
      "Epoch: 0023 cost = 0.132705227\n",
      "Epoch: 0024 cost = 0.127190679\n",
      "Epoch: 0025 cost = 0.120553724\n",
      "Epoch: 0026 cost = 0.119382806\n",
      "Epoch: 0027 cost = 0.110643640\n",
      "Epoch: 0028 cost = 0.107890993\n",
      "Epoch: 0029 cost = 0.102779418\n",
      "Epoch: 0030 cost = 0.101014197\n",
      "Epoch: 0031 cost = 0.097010590\n",
      "Epoch: 0032 cost = 0.091675624\n",
      "Epoch: 0033 cost = 0.090731248\n",
      "Epoch: 0034 cost = 0.087702289\n",
      "Epoch: 0035 cost = 0.082341664\n",
      "Epoch: 0036 cost = 0.077727243\n",
      "Epoch: 0037 cost = 0.079914570\n",
      "Epoch: 0038 cost = 0.075526290\n",
      "Epoch: 0039 cost = 0.072976038\n",
      "Epoch: 0040 cost = 0.073140122\n",
      "Epoch: 0041 cost = 0.068012543\n",
      "Epoch: 0042 cost = 0.068603605\n",
      "Epoch: 0043 cost = 0.066870235\n",
      "Epoch: 0044 cost = 0.065698639\n",
      "Epoch: 0045 cost = 0.061454706\n",
      "Epoch: 0046 cost = 0.059973627\n",
      "Epoch: 0047 cost = 0.062936790\n",
      "Epoch: 0048 cost = 0.058174554\n",
      "Epoch: 0049 cost = 0.056736656\n",
      "Epoch: 0050 cost = 0.053482831\n",
      "Epoch: 0051 cost = 0.054001108\n",
      "Epoch: 0052 cost = 0.050103631\n",
      "Epoch: 0053 cost = 0.051457182\n",
      "Epoch: 0054 cost = 0.050082162\n",
      "Epoch: 0055 cost = 0.045656256\n",
      "Epoch: 0056 cost = 0.046894364\n",
      "Epoch: 0057 cost = 0.048765533\n",
      "Epoch: 0058 cost = 0.047225207\n",
      "Epoch: 0059 cost = 0.045623429\n",
      "Epoch: 0060 cost = 0.044495426\n",
      "Epoch: 0061 cost = 0.041719537\n",
      "Epoch: 0062 cost = 0.038890220\n",
      "Epoch: 0063 cost = 0.040526807\n",
      "Epoch: 0064 cost = 0.037589353\n",
      "Epoch: 0065 cost = 0.039940283\n",
      "Epoch: 0066 cost = 0.042202123\n",
      "Epoch: 0067 cost = 0.040751275\n",
      "Epoch: 0068 cost = 0.037908349\n",
      "Epoch: 0069 cost = 0.034835670\n",
      "Epoch: 0070 cost = 0.037270132\n",
      "Epoch: 0071 cost = 0.036279149\n",
      "Epoch: 0072 cost = 0.035201177\n",
      "Epoch: 0073 cost = 0.035975207\n",
      "Epoch: 0074 cost = 0.034703195\n",
      "Epoch: 0075 cost = 0.032620318\n",
      "Epoch: 0076 cost = 0.035557687\n",
      "Epoch: 0077 cost = 0.030990893\n",
      "Epoch: 0078 cost = 0.035054993\n",
      "Epoch: 0079 cost = 0.031651381\n",
      "Epoch: 0080 cost = 0.031168990\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_batch = len(data_loader)\n",
    "model.train() # 주의사항 drop_out = True\n",
    "for epoch in range(80):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # Forward 계산\n",
    "        hypothesis = model(X)\n",
    "        # Error 계산\n",
    "        cost = loss(hypothesis, Y)\n",
    "        # Backparopagation\n",
    "        cost.backward()\n",
    "        # 가중치 갱신\n",
    "        optimizer.step()\n",
    "\n",
    "        # 평균 Error 계산\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9992499947547913\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    prediction = model(test_x_tensor)\n",
    "    \n",
    "    train_prediction = model(train_x_tensor)\n",
    "    correct_prediction = torch.argmax(train_prediction, 1) == train_y_tensor\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = torch.argmax(prediction, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.Label = predict.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('2021_10_13_5.csv', index= False) # 실습 그대로 한 결과  epoch만 20 0.95370"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1차 시도 : 실습 그대로 한 결과  epoch 20, dropout 0.5  score : 0.95370  \n",
    "2차 시도 : 모든 레이어 파라미터 값 2배씩 증가후 코스트 기반으로 epcoh 4로 감소 score : 0.95760  \n",
    "3차 시도 : 실습과 모두 같게하기 score : 0.96840  \n",
    "4차 시도 : 3차시도 중 cost가 가장 낮았던 epoch 4까지 진행 score : 0.96690  \n",
    "5차 시도 : 3차시도에서 epoch 100으로 증가 score : 0.12100\n",
    "6차 시도 : 배치 사이즈 1000 및 epoch 30으로 진행 : 0.97810  \n",
    "7차 시도 : 배치 사이즈 2000 및 epoch 30으로 진행 : 0.97370  \n",
    "train best score : 0.99924\n",
    "\n",
    "=> 0.981333 일 경우 0.97090이 나옴 :baseline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
