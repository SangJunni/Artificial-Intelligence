{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650 Ti'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('pca_train.csv')\n",
    "test = pd.read_csv('pca_test.csv')\n",
    "submit = pd.read_csv('sample_submission.csv')\n",
    "train_y =pd.read_csv('train_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.227718</td>\n",
       "      <td>-2.070960</td>\n",
       "      <td>0.674094</td>\n",
       "      <td>-0.742135</td>\n",
       "      <td>0.309149</td>\n",
       "      <td>-4.006772</td>\n",
       "      <td>-0.664624</td>\n",
       "      <td>0.533987</td>\n",
       "      <td>0.024594</td>\n",
       "      <td>-0.195856</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.114192</td>\n",
       "      <td>-0.605770</td>\n",
       "      <td>0.491399</td>\n",
       "      <td>-0.166693</td>\n",
       "      <td>1.289197</td>\n",
       "      <td>-0.403863</td>\n",
       "      <td>0.238731</td>\n",
       "      <td>2.166737</td>\n",
       "      <td>-0.106487</td>\n",
       "      <td>1.486114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6.081077</td>\n",
       "      <td>-1.960213</td>\n",
       "      <td>0.846482</td>\n",
       "      <td>-0.932816</td>\n",
       "      <td>-0.050208</td>\n",
       "      <td>-4.082826</td>\n",
       "      <td>-0.449032</td>\n",
       "      <td>0.647842</td>\n",
       "      <td>0.417809</td>\n",
       "      <td>0.073842</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000466</td>\n",
       "      <td>-1.175968</td>\n",
       "      <td>0.299093</td>\n",
       "      <td>-1.187048</td>\n",
       "      <td>-0.499101</td>\n",
       "      <td>0.738016</td>\n",
       "      <td>0.632842</td>\n",
       "      <td>0.850430</td>\n",
       "      <td>-2.211427</td>\n",
       "      <td>1.083040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.394956</td>\n",
       "      <td>-2.954897</td>\n",
       "      <td>1.600033</td>\n",
       "      <td>-0.479463</td>\n",
       "      <td>-1.217065</td>\n",
       "      <td>-3.986472</td>\n",
       "      <td>-0.812934</td>\n",
       "      <td>0.472509</td>\n",
       "      <td>1.536917</td>\n",
       "      <td>1.989765</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.703212</td>\n",
       "      <td>0.713673</td>\n",
       "      <td>0.330699</td>\n",
       "      <td>0.036953</td>\n",
       "      <td>-0.204944</td>\n",
       "      <td>0.930597</td>\n",
       "      <td>-0.693151</td>\n",
       "      <td>-0.572443</td>\n",
       "      <td>0.835598</td>\n",
       "      <td>-0.751483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.681355</td>\n",
       "      <td>-2.055031</td>\n",
       "      <td>1.144864</td>\n",
       "      <td>-0.517872</td>\n",
       "      <td>-0.168057</td>\n",
       "      <td>-3.929032</td>\n",
       "      <td>-0.718259</td>\n",
       "      <td>0.555827</td>\n",
       "      <td>0.096472</td>\n",
       "      <td>0.724261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434870</td>\n",
       "      <td>1.571784</td>\n",
       "      <td>-1.266089</td>\n",
       "      <td>1.584173</td>\n",
       "      <td>-0.290301</td>\n",
       "      <td>0.068907</td>\n",
       "      <td>-1.148258</td>\n",
       "      <td>1.904273</td>\n",
       "      <td>0.322937</td>\n",
       "      <td>-0.318100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.716713</td>\n",
       "      <td>-2.163729</td>\n",
       "      <td>0.877930</td>\n",
       "      <td>-0.605268</td>\n",
       "      <td>0.082372</td>\n",
       "      <td>-4.261466</td>\n",
       "      <td>-0.679734</td>\n",
       "      <td>0.739369</td>\n",
       "      <td>0.490033</td>\n",
       "      <td>0.546437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626112</td>\n",
       "      <td>-0.435030</td>\n",
       "      <td>2.112485</td>\n",
       "      <td>1.101894</td>\n",
       "      <td>1.746205</td>\n",
       "      <td>-0.445612</td>\n",
       "      <td>-1.518138</td>\n",
       "      <td>0.299177</td>\n",
       "      <td>-0.020655</td>\n",
       "      <td>0.234824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27666</th>\n",
       "      <td>-6.047007</td>\n",
       "      <td>-2.072704</td>\n",
       "      <td>0.668214</td>\n",
       "      <td>-0.254932</td>\n",
       "      <td>0.099894</td>\n",
       "      <td>-1.477478</td>\n",
       "      <td>-0.703836</td>\n",
       "      <td>-0.327026</td>\n",
       "      <td>0.504125</td>\n",
       "      <td>0.222820</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.449840</td>\n",
       "      <td>-0.050902</td>\n",
       "      <td>-1.240334</td>\n",
       "      <td>-0.750522</td>\n",
       "      <td>-1.168852</td>\n",
       "      <td>0.048051</td>\n",
       "      <td>0.432534</td>\n",
       "      <td>-0.003478</td>\n",
       "      <td>-0.609472</td>\n",
       "      <td>-0.348196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27667</th>\n",
       "      <td>-6.569392</td>\n",
       "      <td>-1.932956</td>\n",
       "      <td>0.602381</td>\n",
       "      <td>0.253941</td>\n",
       "      <td>-0.341952</td>\n",
       "      <td>4.064471</td>\n",
       "      <td>-1.502157</td>\n",
       "      <td>-2.467482</td>\n",
       "      <td>0.281797</td>\n",
       "      <td>0.812378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721433</td>\n",
       "      <td>1.197452</td>\n",
       "      <td>-0.700384</td>\n",
       "      <td>-3.483315</td>\n",
       "      <td>-0.371596</td>\n",
       "      <td>0.478422</td>\n",
       "      <td>-1.537939</td>\n",
       "      <td>2.030344</td>\n",
       "      <td>-1.080110</td>\n",
       "      <td>-0.409972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27668</th>\n",
       "      <td>-6.232087</td>\n",
       "      <td>-1.834862</td>\n",
       "      <td>2.097659</td>\n",
       "      <td>-0.566552</td>\n",
       "      <td>-0.288520</td>\n",
       "      <td>-4.034954</td>\n",
       "      <td>0.457435</td>\n",
       "      <td>0.315611</td>\n",
       "      <td>0.981373</td>\n",
       "      <td>0.483152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662459</td>\n",
       "      <td>-1.293272</td>\n",
       "      <td>0.067110</td>\n",
       "      <td>0.357502</td>\n",
       "      <td>-0.155424</td>\n",
       "      <td>-0.658622</td>\n",
       "      <td>2.016063</td>\n",
       "      <td>-0.359339</td>\n",
       "      <td>0.993638</td>\n",
       "      <td>0.130081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27669</th>\n",
       "      <td>-6.387326</td>\n",
       "      <td>-0.387639</td>\n",
       "      <td>-1.090173</td>\n",
       "      <td>1.499431</td>\n",
       "      <td>0.629389</td>\n",
       "      <td>31.163396</td>\n",
       "      <td>-3.186039</td>\n",
       "      <td>-12.114586</td>\n",
       "      <td>-0.543894</td>\n",
       "      <td>-1.469931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.838120</td>\n",
       "      <td>0.584897</td>\n",
       "      <td>-1.355164</td>\n",
       "      <td>-1.358166</td>\n",
       "      <td>1.344522</td>\n",
       "      <td>-0.526878</td>\n",
       "      <td>-0.230260</td>\n",
       "      <td>-0.459776</td>\n",
       "      <td>2.507944</td>\n",
       "      <td>-1.379322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27670</th>\n",
       "      <td>-6.317132</td>\n",
       "      <td>-2.159943</td>\n",
       "      <td>1.085279</td>\n",
       "      <td>-0.551308</td>\n",
       "      <td>-0.256207</td>\n",
       "      <td>-4.151564</td>\n",
       "      <td>-0.860211</td>\n",
       "      <td>0.470046</td>\n",
       "      <td>0.246312</td>\n",
       "      <td>0.981830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169673</td>\n",
       "      <td>0.152567</td>\n",
       "      <td>0.655538</td>\n",
       "      <td>0.094223</td>\n",
       "      <td>-0.643895</td>\n",
       "      <td>-0.257323</td>\n",
       "      <td>0.054573</td>\n",
       "      <td>-0.807560</td>\n",
       "      <td>0.247731</td>\n",
       "      <td>2.318635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27671 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4          5         6  \\\n",
       "0     -6.227718 -2.070960  0.674094 -0.742135  0.309149  -4.006772 -0.664624   \n",
       "1     -6.081077 -1.960213  0.846482 -0.932816 -0.050208  -4.082826 -0.449032   \n",
       "2     -6.394956 -2.954897  1.600033 -0.479463 -1.217065  -3.986472 -0.812934   \n",
       "3     -6.681355 -2.055031  1.144864 -0.517872 -0.168057  -3.929032 -0.718259   \n",
       "4     -5.716713 -2.163729  0.877930 -0.605268  0.082372  -4.261466 -0.679734   \n",
       "...         ...       ...       ...       ...       ...        ...       ...   \n",
       "27666 -6.047007 -2.072704  0.668214 -0.254932  0.099894  -1.477478 -0.703836   \n",
       "27667 -6.569392 -1.932956  0.602381  0.253941 -0.341952   4.064471 -1.502157   \n",
       "27668 -6.232087 -1.834862  2.097659 -0.566552 -0.288520  -4.034954  0.457435   \n",
       "27669 -6.387326 -0.387639 -1.090173  1.499431  0.629389  31.163396 -3.186039   \n",
       "27670 -6.317132 -2.159943  1.085279 -0.551308 -0.256207  -4.151564 -0.860211   \n",
       "\n",
       "               7         8         9  ...       246       247       248  \\\n",
       "0       0.533987  0.024594 -0.195856  ... -2.114192 -0.605770  0.491399   \n",
       "1       0.647842  0.417809  0.073842  ... -1.000466 -1.175968  0.299093   \n",
       "2       0.472509  1.536917  1.989765  ... -1.703212  0.713673  0.330699   \n",
       "3       0.555827  0.096472  0.724261  ...  0.434870  1.571784 -1.266089   \n",
       "4       0.739369  0.490033  0.546437  ...  0.626112 -0.435030  2.112485   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "27666  -0.327026  0.504125  0.222820  ... -1.449840 -0.050902 -1.240334   \n",
       "27667  -2.467482  0.281797  0.812378  ...  0.721433  1.197452 -0.700384   \n",
       "27668   0.315611  0.981373  0.483152  ...  0.662459 -1.293272  0.067110   \n",
       "27669 -12.114586 -0.543894 -1.469931  ... -0.838120  0.584897 -1.355164   \n",
       "27670   0.470046  0.246312  0.981830  ...  0.169673  0.152567  0.655538   \n",
       "\n",
       "            249       250       251       252       253       254       255  \n",
       "0     -0.166693  1.289197 -0.403863  0.238731  2.166737 -0.106487  1.486114  \n",
       "1     -1.187048 -0.499101  0.738016  0.632842  0.850430 -2.211427  1.083040  \n",
       "2      0.036953 -0.204944  0.930597 -0.693151 -0.572443  0.835598 -0.751483  \n",
       "3      1.584173 -0.290301  0.068907 -1.148258  1.904273  0.322937 -0.318100  \n",
       "4      1.101894  1.746205 -0.445612 -1.518138  0.299177 -0.020655  0.234824  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "27666 -0.750522 -1.168852  0.048051  0.432534 -0.003478 -0.609472 -0.348196  \n",
       "27667 -3.483315 -0.371596  0.478422 -1.537939  2.030344 -1.080110 -0.409972  \n",
       "27668  0.357502 -0.155424 -0.658622  2.016063 -0.359339  0.993638  0.130081  \n",
       "27669 -1.358166  1.344522 -0.526878 -0.230260 -0.459776  2.507944 -1.379322  \n",
       "27670  0.094223 -0.643895 -0.257323  0.054573 -0.807560  0.247731  2.318635  \n",
       "\n",
       "[27671 rows x 256 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_tensor = torch.FloatTensor(train.values).to(device)\n",
    "train_y_tensor = torch.LongTensor(train_y.label).to(device)\n",
    "\n",
    "test_x_tensor = torch.FloatTensor(test.values).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN,self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(256,198, bias = True)\n",
    "        self.linear2 = torch.nn.Linear(198,198, bias = True)\n",
    "        self.linear3 = torch.nn.Linear(198, 198, bias = True)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        return out\n",
    "\n",
    "model = NN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "total_epoch = 50\n",
    "\n",
    "for epoch in range(1, total_epoch + 1):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(train_x_tensor)\n",
    "    cost = loss(hypothesis, train_y_tensor)\n",
    "    cost.backward()\n",
    "        \n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 ==0:\n",
    "        print(epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model(test_x_tensor)\n",
    "    train_hypothesis = model(train_x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8855841856094828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "train_predict = torch.argmax(train_hypothesis, dim =1)\n",
    "print(accuracy_score(train_predict.detach().cpu(), train_y.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = torch.argmax(prediction, dim = 1)\n",
    "submit.label = predict.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13624</th>\n",
       "      <td>13624</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13625</th>\n",
       "      <td>13625</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13626</th>\n",
       "      <td>13626</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13627</th>\n",
       "      <td>13627</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13628</th>\n",
       "      <td>13628</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13629 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label\n",
       "0          0    113\n",
       "1          1    170\n",
       "2          2     68\n",
       "3          3     28\n",
       "4          4    121\n",
       "...      ...    ...\n",
       "13624  13624    166\n",
       "13625  13625     69\n",
       "13626  13626     23\n",
       "13627  13627     68\n",
       "13628  13628    117\n",
       "\n",
       "[13629 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('2021_10_11_02.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "    def __intit(self):\n",
    "        super(NN,self).__init__()\n",
    "        linear\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return out\n",
    "    \n",
    "nmodel = NN().to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
